optimizer:
  name: adam
  lr: 1.0e-3
  weight_decay: 0

train:
  epoch: 3000
  batch_size: 4096
  save_model: true
  loss: pairwise
  test_step: 3
  reproducible: true
  seed: 2023
  patience: 5

test:
  metrics: [recall, ndcg]
  k: [5, 10, 20]
  batch_size: 1024

data:
  type: general_cf
  name: amazon

model:
  name: simgcl_mv
  # general parameters here
  keep_rate: 1.0
  embedding_size: 32
  intent_num: 128
  conformity_num: 64
  # augmentation: edge_drop

  # dataset-specific parameters here
  layer_num: 3
  reg_weight: 1.0e-5
  cl_weight: 1.0e-1
  cl_temperature: 0.2
  kd_weight: 1.0e-2
  kd_temperature: 0.2
  eps: 0.9
  # for amazon_movie
  amazon_movie:
    layer_num: 3
    reg_weight: 1.0e-6
    cl_weight: 2.0e-2
    cl_temperature: 0.1
    kd_weight: 1.0e-2
    kd_temperature: 0.2
    kd_int_weight: 3.0e-2
    kd_int_temperature: 0.2
    kd_int_weight_2: 1.0e-3
    kd_int_weight_3: 1.0e-4
    eps: 0.1

    kd_conf_weight: 2.0e-3       # Conformity 채널 KD Loss 가중치
    kd_conf_temperature: 0.5   # Conformity 채널 KD Loss 온도
    #kd_conf_weight_3: 1.0e-7     # Conformity 채널 Momentum Loss 가중치
    hcl_weight: 1.0e-2           # Hierarchical Contrastive Loss 가중치
    hcl_temperature: 0.2       # Hierarchical Contrastive Loss 온도

  # for amazon_book
  amazon_book:
    layer_num: 3
    reg_weight: 1.0e-5
    cl_weight: 1.0e-1
    cl_temperature: 0.2
    kd_weight: 1.0e-2
    kd_temperature: 0.2
    kd_int_weight: 2.0e-2
    kd_int_temperature: 0.1
    kd_int_weight_2: 5.0e-4
    kd_int_weight_3: 1.0e-4
    eps: 0.9
    
    kd_conf_weight: 1.0e-3       # Conformity 채널 KD Loss 가중치
    kd_conf_temperature: 0.5   # Conformity 채널 KD Loss 온도
    #kd_conf_weight_3: 1.0e-7     # Conformity 채널 Momentum Loss 가중치
    hcl_weight: 1.0e-2           # Hierarchical Contrastive Loss 가중치
    hcl_temperature: 0.2       # Hierarchical Contrastive Loss 온도